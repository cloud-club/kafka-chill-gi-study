## Chapter 1. Meet Kafka
___

> 모든 애플리케이션은 데이터를 만들고, 그 데이터는 next thing을 알려줄 중요한 정보가 된다.
> 
> 예를 들면, 아마존에서 우리가 관심 있는 항목을 클릭하면, 추천 항목에 뜨게되며 모든 기업이 데이터로 움직인다는 것을 의미한다.
___

### Publish/Subscribe Messaging

- pub/sub 메시징은 데이터(메시지)의 발신자(publisher)가 특정 수신자(subscriber)에게 직접적으로 데이터를 보내지 않는 특징을 가진 패턴
- publisher는 메시지를 어떤 식으로든 분류하고, subscriber는 메시지를 수신하기 위해 구독(subscribe)하는 형태

pub/sub 사례는 단순한 메시지 큐 혹은 프로세스 간 통신 채널로 시작하는 것과 동일하다 

예를들어, 애플리케이션의 메트릭을 수집하는 서버가 있고 애플리케이션이 있다면 간단하게 서로 `직접 연결`하여 메트릭을 push하고 모니터링할수 있다.

추후에 더 많은 애플리케이션으로부터 메트릭을 수집하거나, 데이터를 분석하는 등의 새로운 서비스를 시작하게 된다면 애플리케이션에 직접 연결을 다시 수행해야하며 점점 많은 연결이 생기게되고 이는 추적을 어렵게 만든다.
<p align="center"><img width="966" alt="image" src="https://github.com/user-attachments/assets/cac04aa5-d90c-45d2-b780-7041badf8278" /></p>

여기서 생기는 기술 부채는 너무 명확하여 이를 해결하기 위해 다음과 같이 구축할 수 있다.
- 모든 애플리케이션으로부터 측정 지표를 받는 단일 애플리케이션을 설정하고, 필요한 모든 시스템이 해당 측정 지표를 쿼리할 수 있는 서버를 제공
<p align="center"><img width="966" alt="image" src="https://github.com/user-attachments/assets/1b4c39f9-e56b-45e1-b6ee-2cffc269aac8" /></p>

아키텍처 복잡성을 줄였으며 이는 publish/subscribe messaging system을 구축한 것이다.
___

### Individual Queue Systems

메트릭, 로깅, 사용자 추적 3개의 job에 대하여 pub/sub system을 구축

3개의 시스템으로 분리하였지만 상황에 따라 중복되어 메시지 큐가 쌓일 수 있으며, 위에서 살펴본 상황과 결국 동일한 상황에 놓이게 될 것임 
-> 서비스가 확장하면서 더 다양한 지표를 얻고자 한다면 중복되는 pub/sub system이 확장될 것

비즈니스가 확장되어도 single centralized system을 구축하고 싶음
___

### Enter Kafka

아파치 카프카가 위에서 설명하는 문제를 해결하는 publish/subscribe messaging system으로 개발되었음
-> `분산 커밋 로그` 또는 `분산 스트리밍 플랫폼`이라고 부름

파일 시스템 또는 데이터베이스 커밋 로그는 모든 트랜잭션의 지속적인 기록을 제공하여 시스템의 상태를 일관되게 구축하기 위해 재생될 수 있도록 설계된 것 같이
카프카 내의 데이터는 내구성과 순서에 맞게 저장되고, 데이터는 시스템 내에서 분산되어 장애에 대한 추가적인 보호와 확장에 유연한 성능을 보인다.
___

### Messages and Batches

- 카프카 내의 데이터 단위는 메시지 (DB로 따지면 행, 레코드와 유사)
- 카프카에 관한 메시지는 단순히 바이트 배열이므로, 그 안에 포함된 데이터는 카프카에 특정 형식이나 의미를 가지지 않음
- 메시지는 메타데이터를 선택적으로 키값으로 설정할 수 있음
  - 키 값은 파티션에 기록될 때 사용되는데, 키 값을 해시하여 토픽의 총 파티션 수로 나눈 몫으로 메시지의 파티션 번호를 선택함
- 효율성을 위해 메시지는 카프카에 배치 형식으로 저장되며, 배치는 동일한 토픽 및 파티션에 생성되는 메시지 모음이다.
___

### Schemas

- 메시지는 카프카에선 바이트 배열이지만, 쉽게 이해하기 위한 스키마를 적용하는 것이 좋다.
- 애플리케이션에 따라 메시지 스키마엔 다양한 옵션이 존재하며 JSON, XML이 사람이 읽기엔 좋음
  - 카프카 개발자는 원래 하둡용 직렬화 프레임워크인 Apache Avro 사용을 선호
- `Avro`는 컴팩트한 직렬화 형식, 메시지 페이로드와 분리된 스키마(변경 시 코드를 생성할 필요가 없음), 이전 버전과의 호환성 및 이후 버전과의 호환성을 모두 지원
- 메시지 읽기, 쓰기를 분리하기 위해선 일관된 데이터 형식이 중요
___

### Topics and Partitions

카프카의 메시지는 토픽으로 분류되며 토픽은 데이터베이스 테이블 또는 파일 시스템의 폴더라고 표현할 수 있다.

- 토픽은 추가적으로 여러 파티션으로 나뉘며, 커밋 로그로 말하면 파티션은 단일 로그를 말하고, 이런 파티션들을 순서대로 읽는방식
- 파티션은 여러 서버에 호스팅될 수 있으며, 단일 토픽이 여러 서버에 걸쳐 수평적으로 확장되어 단일 서버의 능력보다 훨씬 뛰어난 성능을 제공할 수 있음을 의미한다 또한, 파티션을 복제하여 한 서버가 실패할 경우 다른 서버가 동일한 파티션의 복사본을 저장할 수 있다.
- `스트림`이라는 용어는 카프카에서 파티션 수에 관계없이 단일 데이터 토픽으로 간주함
- pub to sub으로 이동하는 단일 스트림은 하둡과같이 대량 데이터에서 작동하도록 설계된 방식과 비교할 수 있음
<p align="center"><img width="558" alt="image" src="https://github.com/user-attachments/assets/aa61721f-d290-41d2-9d5a-5e33aa236cf7" /></p>

___

###

