# 5주차

범위: 7장 + 인프런 강의

# Ch7. 신뢰성 있는 데이터 전달

신뢰성 있는 애플리케이션을 개발하고자 한다면 카프카가 제공하는 보장을 이해하는 것은 필수적이다. 

## 🌳 카프카가 보장하는 것(신뢰성 보장)

- 파티션 내부 메시지의 순서 보장
- 클라이언트가 쓴 메시지는 모든  in-sync replica(ISR) 파티션에 쓰여야만 커밋된 것으로 간주
- 커밋된 메시지는 최소 1개의 작동 가능한 레플리카가 남아있는 한 유실되지 않는다.
- 컨슈머는 커밋된 메시지만 읽을 수 있다.

## 🌳 복제의 영향

- 파티션은 메시지의 물리적인 분할 단위이다. 보통 브로커에 분산 저장되며 각각 독립적인 offset 을 가지기에 순서가 보장되는 특성이 있다.
- 레플리카는 파티션의 리더 레플리카이거나 혹은 특정 조건을 만족하는 팔로워일 경우 인싱크 레플리카로 본다
- 리더 레플리카가 작동불능 상태가 될 경우 인싱크 레플리카 중 하나가 리더가 된다.
- 파티션은 다수의 레플리카를 가질 수 있으며 그 중 하나가 리더 레플리카이다.

### 🌿 In-sync 레플리카

레플리카는 파티션의 리더 레플리카이거나 아니면 아래의 조건을 만족하는 팔로워 레플리카인 경우 인-싱크 상태인 것으로 간주된다.

- 주키퍼와의 활성 세션이 있다.  즉, 최근 6초 사이(설정 가능)에 주키퍼로 하트비트를 전송했다.
- 최근 10초 사이(설정 가능) 리 더로부터 메시지를 읽어왔다.
- 최근 10초 사이에 리더로부터 읽어 온 메시지들이 가장 최근 메시지이다.

## 🌳 브로커설정

- `replication.factor` : 파티션의 복제본 수
- `unclean.leader.election.enable` : ISR 외의 레플리카가 리더가 될 수 있는지 여부
- `min.insync.replicas` : in-sync 레플리카의 최소 수.  이 수보다 적은 수의 레플리카가 있을 경우 커밋이 실패한다.

### 🌿 replication factor

- 클라우드 환경에서 카프카를 운용할 경우 availability zone을 랙과 비슷한 개념으로 사용하는 것이 일밙거이다.

### 🌿 unclean.leader.election.enable

- leader가 다운되었을 때 ISR 내의 레플리카 중 하나가 리더가 되는데, 이때 ISR 외의 레플리카가 리더가 되는 것을 허용할지 여부를 결정하는 과정
- leader가 clean하다는 것은 리더가 될 레플리카가 ISR 내에 있는 것을 의미
- 기본값은 false

`unclean.leader.election.enable=**false**`

**데이터 정합성 측면**

- 정합성은 기본적으로 일관성의 문제
- ISR 내의 레플리카만 리더가 될 수 있어 데이터 손실 없음
- 모든 컨슈머는 동일한 데이터를 보게 됨

**가용성 측면**

- 모든 ISR이 다운되면 파티션 전체가 사용 불가능
- 서비스 중단 시간(downtime) 발생 가능성 높음
- 복구를 위해 ISR 중 하나가 다시 복구 될 때까지 대시 필요

`unclean.leader.election.enable=**true**`

**데이터 정합성 측면**

- 데이터 손실 발생 가능
- 이전 리더가 가진 커밋된 메시지들이 유실될 수 있음
- 일시적으로 다른 컨슈머들이 서로 다른 데이터를 볼 수 있음

**가용성 측면**

- 높은 가용성 보장
- ISR 외의 레플리카도 리더가 될 수 있어 서비스 중단 최소화
- 빠른 복구 가능

### 🌿 min.insync.replicas

- 커밋된 데이터를 2개 이상의 레플리카에 쓸 경우, `min.insync.replicas` 를 보다 높게 잡아줄 필요가 있다.

## 🌳 신뢰성 있는 시스템에서 Producer 사용하기

사용 가능한 가장 높은 신뢰성 설정을 브로커에 적용하더라도, 프로듀서 역시 신뢰성이 있도록 설정을 잡아 주지 않는다면 시스템 전체로서는 여전히 데이터가 유실될 수 있다.

- `acks` : acknowledgement, 프로듀서가 메시지 응답을 성공으로 판정하는 기준에 대한 설정. 안정성과 성능간 트레이드 오프와 관련
    
    > 메시지가 제대로 전달됐다고 확인하는 기준
    > 
- [`delivery.timeout.ms`](http://delivery.timeout.ms) :  프로듀서는 이 시간 간격 안에 있는 메시지 전송을 재시도
    
    > 메시지 전송을 포기하기 전에 얼마나 오래 시도할 지 결정하는 시간 제한
    > 
- 전송 실패한 메시지를 계속 재시도하는 것은 메시지가 중복된 위험을 내포한다.

### 🌿 데이터 손실 시나리오

1. 브로커는 안정적, 프로듀서는 acks=1 :
    - 3개의 레플리카와 unclean 리더 선출이 비활성화된 상태
    - 프로듀서가 acks=1로 메시지 전송
    - 메시지가 리더에 기록되지만 동기화 레플리카에는 아직 미기록
    - 리더가 “성공적으로 기록됨” 응답 후 즉시 크래시되어, 데이터가 레플리카로 복제되지 않음
    - 다른 레플리카가 새 리더가 되지만 해당 메시지를 받지 못함
    - 결과 : 프로듀서는 성공했다고 생각하지만 실제로는 메시지 손실
2. 브로커는 안정적, 프로듀서는 acks=all, 오류 처리 부족:
    - 3개의 레플리카와 unclean 리더 선출이 비활성화된 상태
    - 메시지 작성 시도 중 파티션 리더가 크래시 되어, 새로운 리더를 선출하는 과정 중임
    - 이때 Kafka가 Producerㅇ게 “Leader not Available” 오류를 응답
    - 프로듀서가 이 오류를 받았을 때, 적절히 대응하지 않으면 문제 발생
    - 즉, 프로듀서 코드가 이 오류를 받고 재시도하는 로직이 없다면, 메시지는 아무곳에도 저장되지 않고 영영 사라짐

### 🌿 주의해야 할 Producer 핵심 사항

- 신뢰성 요구사항에 맞는 acks 구성 사용
- 구성과 코드에서 오류를 올바르게 처리

### 🌿 잘못된 메시지의 처리 방식

> 재시도는 기본 카프카 내장 기능에 맡기고, 특별한 비즈니스 요구사항이 있을 때만 추가 로직을 구현하는 것을 권장
> 
- 요구 사항에 따라 에러를 어떤 식으로 처리할 지가 달라진다.
- 메시지 재전송이 에러 핸들러가 하는 일의 전부라면, 프로듀서의 재전송 기능을 쓰는 편이 더 낫다.

## 🌳 신뢰성 있는 시스템에서 Consumer 사용하기

컨슈머는 카프카에 커밋된 데이터만 읽을 수 있다. 즉, 모든 인-싱크 레플리카에 쓰여진 다음부터 읽을 수 있는 것이다. 다르게 말하면, 컨슈머는 일관성이 보장되는 데이터만 읽는다.

- offset commit : 컨슈머가 특정 파티션의 offset까지의 메시지를 안전하게 처리할 수 있다ㄱ 보장할 수 있는 지점을 카프카에 기록하는 작업. 이는 단순히 처리 완료 신호가 아니라, 복구가가능한 지점을 표시하는 것에 가까움. 특정 offset을 commit했다는 것은 offset 이전의 모든 메시지도 처리되었음을 의미
- [`group.id`](http://group.id)
    - 여러 컨슈머가 같은 그룹 ID를 가지면, 토픽의 파티션을 나눠서 읽는다.
    - 모든 메시지를 혼자 읽고 싶다면 고유한 groupd.id가 필요하다
- `auto.offset.reset`
    - 커밋된 오프셋이 없을 때나 컨슈머가 브로커에 없는 오프셋을 요청할 때 컨슈머가 어떻게 해야 할 지를 결정
    - `earliest` : (파티션 맨 앞부터 읽기 시작) 유효한 오프셋이 없을 때 파티션의 처음부터 시작한다.  메시지 중복 처리 가능성이 있지만 데이터 손실을 최소화한다.
    - `latest` :  (파티션 맨 끝부터 읽기 시작) 파티션의 끝에서 시작한다. 중복 처리는 줄지만 메시지를 놓칠 수 있다,.
- `enable.auto.commit`
    - 일정한 시간에 맞춰 자동으로 오프셋을 커밋핧 지, 수동으로(코드에서) 커밋할 지 결정한다.
    - 자동 커밋은 간단하지만 제어력이 떨어진다.
    - 복잡한 처리 로직이 있다면 수동 커밋이 필요하다.
- `auto.commit.interval.ms`
    - 오프셋을 자동으로 커밋할 경우, 이 설정을 사용하여 커밋되는 주기를 설정할 수 있다.
    - 기본값은 5초
    - 더 자주 커밋하면 오버헤드는 증가하지만 중복 처리는 줄어든다.

### 🌿 컨슈머에서 명시적으로 오프셋 커밋하기

> 데이터를 신뢰성 있게 다루는 컨슈머를 개발할 때, 고려해야 할 중요한 사항들
> 
- 메시지 처리 먼저, 오프셋 커밋은 나중에
    - 항상 메시지를 처리한 후에 오프셋을 커밋해야 한다.
    - 처리하지 않은 메시지의 오프셋을 커밋하면 메시지 손실이 발생할 수 있다
- 커밋 빈도는 성능과 크래시 발생 시 중복 개수 사이의 트레이드 오프다
    - 자주 커밋하면 장애 시 중복이 줄지만 성능이 저하된다.
    - 매우 낮은 처리량의 토픽에서만 메시지마다 커밋하라.
- 정확한 시점에 정확한 오프셋을 커밋하자
    - 읽은 마지막 오프셋이 아닌, 처리한 마지막 오프셋 이후의 값을 커밋해야 한다.
- 리밸런싱
    - 컨슈머 리밸런싱은 피할 수 없으니 적절히 처리해야 한다.
    - 파티션이 회수되기 전에 오프셋을 커밋하고, 새 파티션이 할당될 때 상태를 정리하라.
- 컨슈머는 재시도를 해야할 수도 있다.
- 컨슈머가 상태를 유지해야할 수도 있다.

> dead letter queue : 재처리가 불가능한 메시지를 보관하는 큐
>
