(... Request Processing까지의 내용 ...)

# 1. 클러스터와 컨트롤러

## ZooKeeper 기반 클러스터 구성

Kafka는 분산 메시지 시스템으로, 여러 개의 브로커들이 함께 클러스터를 구성해서 데이터를 처리한다.  
그런데 이 브로커들이 언제 살아있고, 언제 죽었는지를 Kafka가 알 수 있게 하는 것이 바로 **ZooKeeper**이다.  
ZooKeeper는 Kafka 클러스터의 ‘감시자’ 같은 역할이라고 생각할 수 있다.

Kafka에서는 ZooKeeper를 통해 브로커의 생사 여부, 클러스터 멤버십, 컨트롤러 선출 등을 처리한다.  
즉, 브로커들의 상태를 관리하기 위해 ZooKeeper를 사용하는 것이다.

### 브로커 시작 시 ZooKeeper와의 상호작용

1. 각 Kafka 브로커는 고유한 ID를 부여받고, 보통 설정 파일에서 지정되거나 자동 생성된다.
2. 브로커는 실행될 때 ZooKeeper에 자신을 **ephemeral node**로 등록한다.  
   이는 브로커가 죽거나 연결이 끊기면 자동으로 제거된다.  
   → 브로커가 ‘나 살아있어요’ 하고 등록하는 셈이다.
3. 다른 구성요소는 이 경로(`/brokers/ids`)를 감시하고 있다.  
   Kafka에서 다른 브로커들이나 컨트롤러는 누가 등록되고 사라지는지를 실시간 감시할 수 있다.

📌 브로커가 강제 종료되거나 ZooKeeper와 연결이 끊기면 해당 ephemeral node는 자동 삭제된다.  
📌 브로커가 다시 특정 ID로 재시작하면, 이전에 담당하던 파티션과 토픽 정보를 재활용하여 클러스터에 빠르게 복귀한다.


## Kafka에서 컨트롤러의 역할

Kafka는 여러 대의 브로커가 함께 동작하는 **분산 시스템**이다.  
그렇기 때문에 누군가는 **지휘자** 역할을 맡아 전체 브로커들을 조율해줘야 하는데, 이 지휘자 역할을 하는 것이 바로 Kafka의 컨트롤러다.

- Kafka 클러스터에는 항상 **하나의 컨트롤러**만 존재한다.
- 컨트롤러는 **파티션의 리더 선출**, **클러스터 메타데이터 관리** 역할을 한다.
- ZooKeeper의 `/controller` 노드를 통해 선출되며, 이 노드가 사라지면 다른 브로커가 다시 컨트롤러로 선출된다.
- 특정 브로커가 다운되면, 해당 브로커가 리더였던 파티션의 **새 리더를 선출**하고, 메타데이터 갱신 정보를 모든 브로커에게 전달한다.

### 왜 컨트롤러가 필요할까?

Kafka에서는 각 파티션에 대해 하나의 리더를 정해야 한다.  
프로듀서와 컨슈머는 항상 리더와 통신해야만 메시지를 주고받을 수 있기 때문이다.

그런데 리더 브로커가 꺼지면 해당 파티션은 더 이상 클라이언트 요청을 처리할 수 없다.  
→ 이때 **컨트롤러가 개입**하여 새로운 리더를 선출하는 것이다.


### 👓 컨트롤러는 어떻게 선출되는가?

1. 브로커들이 동시에 시작되면, 각자 ZooKeeper의 `/controller` 노드를 생성하려 한다.  
   (이 노드는 **선착순 한 명만 만들 수 있는 일회용 좌석** 같은 것)
2. 가장 먼저 만든 브로커가 **컨트롤러가 된다.**
3. 나머지 브로커들은 **"아~ 이미 컨트롤러 있구나"** 하고 감시만 한다.



### 👓 컨트롤러가 꺼지면?

1. ZooKeeper는 컨트롤러와의 연결이 끊기면 `/controller` 노드를 자동 삭제한다.
2. 다른 브로커들은 이 노드를 감시하고 있다가, **컨트롤러 사라짐**을 감지한다.
3. 다시 누가 컨트롤러가 될지 **경쟁**을 시작한다.
4. 선착순으로 노드를 만든 브로커가 **새 컨트롤러**가 된다.



### 👓 컨트롤러가 일시적으로 멈췄다가 다시 살아나는 경우?

→ 중복 컨트롤러 발생 가능성이 있다. 이를 방지하기 위해 Kafka는 **컨트롤러 epoch 번호**를 사용한다.

- 브로커가 메시지를 받을 때 epoch 번호를 확인한다.
- 더 오래된 epoch 번호로부터 받은 메시지는 **무시**한다.
- → 즉, **더 최근에 생성된 컨트롤러만 유효**하게 작동한다.


## KRaft (Kafka Raft)

Kafka 2.8 이후부터는 ZooKeeper 없이 동작 가능한 구조로 전환되고 있으며, 이를 **KRaft**라고 부른다.

기존 Kafka는 ZooKeeper를 따로 운영해야 하고,  
컨트롤러가 바뀌면 ZooKeeper에서 메타데이터를 다시 읽어야 하므로 느리고 복잡하다.  
Kafka 하나만 알아서는 운영이 어렵고, 이중 구성의 부담도 있다.

→ 그래서 Kafka는 **"ZooKeeper 없이도 돌아가야 하지 않을까?"** 하는 방향으로 나아가고 있다.



## Raft 알고리즘이란?

**분산 시스템에서 여러 서버가 하나의 리더를 뽑고, 변경사항을 합의하는 방식**이다.

- 누가 리더가 될지, 어떤 변경을 수용할지를 **다수결로 결정**한다.
- Kafka는 이 Raft 알고리즘을 사용해, **메타데이터를 Kafka 내부 로그로 관리**한다.



### Raft에서 컨트롤러는 어떻게 선출되는가?

Raft는 총 3가지 상태 중 하나를 가진다:

- **Follower**: 기본 상태
- **Candidate**: 리더가 없을 때 자천
- **Leader**: 투표에서 다수득표한 노드

### 선출 과정

1. Follower들은 일정 시간 동안 리더의 heartbeat를 못 받으면 **Candidate**가 된다.
2. Candidate는 **자기 자신을 리더로 뽑아달라**고 투표 요청을 보낸다.
3. 다른 노드(Follower)는 **조건에 따라 단 한 번만 투표**한다.
4. 다수의 투표를 얻은 후보가 **Leader**가 된다.

단, 아무에게나 투표하지는 않는다.

- 후보가 제안한 **메타데이터 로그가 더 최신**일 경우에만 투표한다.
- 이미 투표한 term에서는 **다시 투표하지 않는다**.

---

# 2. 복제 (Replication)

복제는 Kafka의 **고가용성(HA)**과 **데이터 내구성**을 보장하는 핵심 메커니즘이다.

Kafka는 데이터를 유실 없이 빠르게 처리하기 위해 **Replication 구조**를 가진다.


## 리더와 팔로워가 무엇인가?

Kafka는 데이터를 **파티션(partition)** 단위로 나눠서 저장한다.  
예: A라는 토픽 → 3개의 파티션 → 여러 Kafka 브로커에 분산

📌 단, **하나의 브로커에만 저장하면** 브로커 장애 시 데이터 유실 가능  
→ Kafka는 **파티션을 복제**한다.

각 파티션은 다음 두 가지 역할을 가진다:

- **Leader**: 모든 읽기/쓰기 요청을 담당
- **Follower**: 리더의 데이터를 실시간으로 복제

즉, Kafka는 **Leader-Follower 구조**를 따른다.  
리더가 죽으면, 팔로워 중 하나가 **리더가 될 수 있다.**  
→ Kafka는 이렇게 **고가용성**을 보장한다.


## ISR (In-Sync Replica)

**리더와 거의 실시간으로 동기화된 팔로워**를 ISR이라고 부른다.

- 리더가 장애나면 ISR 중 **하나만** 리더로 승격된다.
- ISR 유지 여부는 `replica.lag.time.max.ms` 설정으로 판단한다.

📌 이 시간 이상 지연되면 ISR에서 **제외**된다.  
📌 ISR이 아닌 팔로워는 **리더가 될 수 없다** (데이터 유실 위험).


## Follower는 리더를 어떻게 따라가는가?

1. 팔로워는 리더에게 `FetchRequest`를 보낸다.
2. 예: "나 offset 123까지 받았는데, 다음 메시지 줘!"
3. 리더는 해당 offset 이후 메시지를 전달한다.
4. 팔로워는 디스크에 저장하며 리더를 계속 따라간다.

📌 10초 이상 메시지를 안 받아가거나 너무 느리면 → ISR 탈락  
→ 다음 리더 선출 시 후보에서 제외된다.


## 📖 Follower에서 읽기 기능도 지원된다

과거에는?
- Kafka는 무조건 리더에서만 read가 가능했다.
- 리더 브로커에 트래픽 집중, 지연 증가

지금은?
- **Read from Follower** 기능 도입
- 단, **조건이 있음**:
  - 팔로워도 리더만큼 신뢰할 수 있어야 함
  - **committed message만 읽을 수 있어야 함**

📌 예: 클라이언트가 일본에 있고, 리더는 미국 →  
→ 일본에 있는 팔로워에서 데이터를 읽으면 **지연 시간 감소**

### 지역 기반 읽기를 위한 설정

- 클라이언트 설정: `client.rack=jp-tokyo`
- 브로커 설정: `broker.rack=jp-tokyo`
- 레플리카 선택자 설정:  
  `replica.selector.class=org.apache.kafka.common.replica.RackAwareReplicaSelector`

  ---

  ### 3. 요청 처리 (Request Processing)

   Kafka는 단순한 메시지 큐가 아닌, 내부에서는 복잡한 요청 처리 시스템이 작동하고 있다.
   
   Kafka 브로커는 대부분의 시간을 클라이언트와 통신하고, 요청을 받고 처리하고 응답하는 일에 쓴다.
   
   ### 요청 흐름(어떤 방식으로 요청을 주고받는지)
   
   Kafka는 TCP 기반의 바이너리 프로토콜을 사용한다.
   
   Kafka를 사용하는 모든 클라이언트(파이썬, 자바, C 등등)는 이 프로토콜을 따라서 브로커와 대화한다. 즉, 카프카는 HTTP같은 사람이 읽기 쉬운 포맷이 아니라 빠르고 효율적인 이진 형식으로 메시지를 주고받는다.
   
   Kafka 요청에는 여러 정보가 담겨있고, 모든 요청에는 공통된 header가 있다. 아래 정보들 덕분에 Kafka는 다양한 버전의 클라이언트들과도 문제 없이 통신할 수 있고, 문제가 생겼을 때 로그 추적도 가능하다.
   
   - API key: 요청 종류(메시지 전송, 메시지 읽기, 메타데이터 요청 등)
   - 버전: Kafka 버전이 달라도 호환되도록 하기 위한 필드이다.
   - Correlation ID: 요청과 응답을 연결짓는 고유 ID
   - Client ID: 어떤 애플리케이션에서 보낸 요청인지 식별하는 이름

   ### Kafka는 요청을 어떻게 처리하는지
   
      Kafka 브로커는 요청을 받는 구조를 스레드 구조로 나눠서 처리한다.
      
      1. Acceptor Thread
          
          클라이언트가 Kafka에 연결할 때 소켓을 열어주는 역할을 한다. 새로운 연결이 들어오면 다음 단계로 넘긴다.
          
      2. Processor Thread(Network Thread)
          
          실제로 클라이언트의 요청을 받고, 내부 큐에 집어넣는 역할이다. 처리된 응답은 응답 큐에 넣고, 다시 클라이언트에게 돌려보낸다.
          
      3. I/O Thread(Request Handler)
          
          내부 요청 큐에서 메시지를 꺼내서 실제 로직을 수행한다. 메시지를 저장하거나 읽거나 토픽을 생성하는 등의 역할을 한다.
          
      4. Pugatory(지연 응답 대기실)
          
          어떤 요청은 바로 응답할 수 없을 때 여기에 잠깐 대기시킨다. 컨슈머가 읽을 데이터가 없을 때나 DeleteTopic 요청이 와서 토픽 삭제가 완료될 때까지 대기할 때 등의 상황이 있다.

![image (20)](https://github.com/user-attachments/assets/3b1cdd04-0222-466d-9e62-2105c8f47826)

  ### 주요 요청 종류

   Kafka에서는 대표적으로 아래 세가지 요청이 많이 쓰인다.
   
   1. Produce Request
       
       프로듀서가 메시지를 Kafka에 보낼 때 사용한다. 반드시 해당 파티션의 리더 브로커에게 보내야 한다.
       
   2. Fetch Request
       
       컨슈머나 팔로워가 메시지를 읽을 때 사용한다. 마찬가지로 해당 파티션의 리더 브로커에게 보내야 한다.
       
   3. Admin Request
       
       토픽 생성/삭제, 설정 변경 등 메타데이터 작업에 사용한다.
       
   
   Kafka는 모든 요청에 대해 API 버전이 있어, 브로커와 클라이언트가 서로 다른 버전을 사용할 수 있도록 설계되어 있다.
   
   **⚠️ 요청을 리더 브로커에게  보내지 않으면 생기는 문제**
   
   Kafka는 각 파티션마다 하나의 리더 브로커가 존재하는데, Produce나 Fetch 요청은 반드시 리더에게 보내야 한다.
   
   만약에 다른 브로커에게 보내게 되면, Kafka에서 “Not a Leader for Partition” 에러를 돌려준다. 클라이언트는 이 메시지를 받고, ‘브로커 정보가 바뀌었구나!’ 하고 메타데이터를 새로 요청한다.

  ![image (21)](https://github.com/user-attachments/assets/65ae7dd9-3653-435b-8cac-7adc1313b823)

   ❓ **그렇다면 클라이언트는 리더 브로커를 어떻게 알까?**
   
   Kafka 클라이언트는 주기적으로 또는 필요할 때 Metadata Request를 보낸다.
   
   모든 브로커는 메타데이터를 가지고 있기 때문에 Kafka 클러스터의 아무 브로커에게 메타데이터 요청을 보낸다.
   
   이 요청에는 ‘해당 토픽에 어떤 파티션이 있고, 각 파티션 리더가 누구냐?’같은 정보를 담는다. 그리고 Kafka 브로커는 응답으로 [파티션 목록, 각 파티션의 복제본 정보, 리더가 누구인지]에 대한 정보를 제공한다.
   
   이 정보를 받은 클라이언트는 cache에 저장해두었다가, 다음 요청때 참고해서 올바른 리더 브로커에게 요청을 보내는 것이다.
   
   브로커는 메시지를 처리한 후에 클라이언트에게 ACK를 주고, 클라이언트는 해당 응답을 받음으로써 메시지가 정상적으로 처리되었다고 인식한다.
   
   🔄 이때, 메타데이터는 [metadata.max.age.ms](http://metadata.max.age.ms) 설정에 따라 새로 갱신된다. 이때마다 kafka 클라이언트가 위 설정에 따라 주기적으로 새로 요청한다.
   
   혹은 리더브로커가 바뀌었을 경우,  “Not a Leader” 오류를 받았을 경우 즉시 갱신한다.

   ### Produce Request

Kafka에서 Producer는 메시지를 브로커에 전송하는 역할을 한다.

Produce Request는 클라이언트(=프로듀서)가 Kafka 브로커에게 ‘이 메시지 저장해줘!’ 라고 요청하는 것이다. 그런데 이 메시지가 ‘저장되었다’고 간주되는 조건은 상황에 따라 다를 수 있다. 그 조건을 설정하는게 acks 파라미터다.

0에 가까울수록 가장 빠르지만 데이터 유실 위험이 있고, all로 갈수록 가장 안전하지만 응답이 느려진다는 특징이 있다.

| acks | 동작 방식 |
| --- | --- |
| 0 | 아무 응답도 기다리지 않고 메시지를 보낸 즉시 성공처리 |
| 1 | 리더 브로커만 메시지를 받으면 성공처리 |
| all | 모든 ISR이 복제 완료하면 성공처리 |

Produce Request가 브로커에 도착하면, 브로커는 단순히 저장하는게 아니라 유효성 검사를 거친다. acks값이 0, 1, all 중 하나인 유효한 값인지 이 토픽에 데이터를 쓸 권한이 있는 사용자인지 검증한다.(acks = all인 경우, 메시지를 복제할 ISR이 충분이 살아있지 않으면 메시지를 아예 거부할 수도 있다. → chapter 7에서 더 자세히 나올 내용이다.)

검증이 끝나면, 메시지를 브로커의 로컬 디스크에 기록한다. Kafka가 디스크에 직접 쓰는게 아니라 리눅스 파일시스템 캐시에 먼저 기록한다. 실제 디스크에 언제 저장될지는 OS가 결정하고, Kafka는 메시지가 디스크에 안전히 기록됐는지 기다리지 않는다.


### Fetch Request

Kafka에서 Fetch Request는 컨슈머가 브로커에게 ‘특정 오프셋부터 메시지를 보내줘’라고 요청하는 방식이다.

요청 예시는 아래처럼 여러 파티션에 대해 한꺼번에 메시지를 요청할 수 있는데, 이 때 클라이언트는 각 파티션에 대해 브로커가 응답할 수 있는 데이터 최대 용량도 함께 보낸다. 클라이언트는 응답을 받을 때 메모리에 버퍼를 미리 할당해야하기 때문에 이 제한이 없다면 브로커가 너무 많은 데이터를 보내서 클라이언트 메모리가 부족할 수 있기 때문이다.

ex) 

**"Please send me messages starting at offset 53 in partition 0 of topic Test and messages starting at offset 64 in partition 3 of topic Test."**

Produce Request와 마찬가지로 Fetch Request는 반드시 리더 브로커에게 요청해야한다. 위와 동일한 방식으로 클라이언트는 Metadata Request를 통해 리더 브로커 정보를 알아낸 후, 정확한 브로커에게 Fetch Request를 보내는 구조이다.

아래 도식을 기반으로 살펴보면

1. Producer들이 브로커에게 메시지를 계속 보낸다.
2. Consumer는 Fetch Request를 보낸다.
3. Broker는 바로 응답하지 않고, 메시지가 일정량 쌓일 때까지 기다린다.
4. 메시지가 임계치 이상 도달하면 브로커는 응답을 보내고, Consumer가 수신한다.


![image (22)](https://github.com/user-attachments/assets/79b02eda-a3ee-4382-9d8e-cc46ff7d27c3)


더 자세히 살펴보면, 리더 브로커가 요청을 받으면 ‘요청한 오프셋이 존재하는가’에 대해 유효성 검사를 진행한다. 너무 오래된 메시지는 이미 삭제됐을 수 있다. 혹은 요청한 offset이 아직 존재하지 않는 미래 오프셋일 수도 있다. → 이 경우에는 에러 응답을 클라이언트에 보낸다.

만약 유효한 offset이면, 브로커는 해당 파티션에서 메시지를 읽어서, 요청한 크기까지 앍고 클라이언트에게 메시지를 보낸다.

➕ **Kafka는 최대 응답 크기만 있는 건 아니고, minimum bytes도 설정할 수 있다.**

만약 트래픽이 적은 토픽을 계속 조회하면, 응답에는 거의 데이터가 없으면서 CPU, 네트워크 자원 낭비가 일어난다. 따라서 브로커는 요청을 받고 기다렸다가 메시지가 충분히 쌓이면 그때 응답을 보낸다.
하짐나 어느 정도 시간이 지나면, **그 시점까지 존재하는 데이터만이라도 받아서 처리하는 것이 더 타당**하다. 그래서 클라이언트는 timeout을 정의할 수 있다.

➕ **Zero-Copy 전송**

Kafka는 메시지를 보낼 때 zero-copy 기술을 사용한다. 일반적인 시스템은 

디스크 → 메모리 → 네트워크 전송 순서로 데이터가 전달되지만 Kafka는 디스크(or Linux filesystem cache) → 네트워크 전송으로 중간 버퍼링이나 바이트 복사 작업 없이 전송이 가능하다. 이 방식 덕분에 Kafka는 매우 높은 처리량을 갖는다.

아래 그림은, 클라이언트는 모든 ISR에 기록된 메시지만 읽을 수 있음을 나타낸다. (물론 데이터 복제해야 하는 Follower Replica만 빼고)

컨슈머가 메시지를 요청할 때, 해당 메시지가 모든 ISR에 복제되기 전까지는 해당 메시지는 소비자에게 전송되지 않고, 에러가 아닌 빈 응답으로 돌아온다.

그 이유는, 아직 충분한 수의 Replica에 본제되지 않은 메시지는 안전하지 않다고 간주되기 때문이다.

만약, 리더가 crash → 다른 레플리카가 리더로 승격되었을 때,

모든 ISR에 메시지 복제가 완료되지 않고, 메시지 복제가 덜 된 ISR의 리더로 승격된다면 데이터 유실이 일어날 수 있다. 그 결과 해당 메시지를 읽었던 컨슈머와 나머지 컨슈머들 사이에 데이터 불일치가 생긴다.

따라서 아래 도식에 기반하면 Message 0~2까지만 컨슈머가 읽을 수 있는 데이터 영역이다. (나머지 Replica들이 ISR이라고 했을 때)


![image (23)](https://github.com/user-attachments/assets/2d8e47be-22e7-4962-a334-9946a74b0457)

### Other Requests

### 토픽 생성도 CLI → Kafka 요청 방식으로 전환됨

예전에는 커맨드라인 도구로  ZooKeeper에 직접 접근해서 토픽 목록을 수정함으로써 토픽을 생성했다.

그러나 Kafka 커뮤니티는 이제 `CreateTopicRequest`와 같은 요청을 Kafka 프로토콜에 추가했다. 기타 **Kafka 메타데이터 관리 요청들**도 유사한 방식으로 동작한다.

이제는 **Java 애플리케이션이 Kafka의 AdminClient**를 통해 이런 메타데이터 작업을 수행할 수 있다 (→ AdminClient 내용은 Chapter 5에 자세히 나옴).

이러한 요청들이 Kafka 프로토콜의 일부가 되었기 때문에, ZooKeeper 라이브러리를 사용하지 않는 언어로도 Kafka 브로커에 직접 요청하여 토픽을 생성할 수 있게 되었다.

이 외에

- 버전 호환 자동화를 위한 ApiVesionRequest
- Kafka 요청 버전 진화(항상 브로커를 먼저 업그레이드 할 것을 권장)
- Kafka 브로커간 통신  프로토콜(동일 프로토콜 사용)
- Kafka 프로토콜의 진화

등의 내용이 나와있는데, 이건 나중에 정리하겠다.
