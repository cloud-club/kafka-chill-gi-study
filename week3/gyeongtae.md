# Chapter 4. 카프카 컨슈머: 카프카에서 데이터 읽기
- 카프카에서 데이터를 읽는 애플리케이션은 토픽을 구독하고 구독한 토픽들로부터 메시지를 받기 위해 KafkaConsumer를 사용함.

## 4.1 카프카 컨슈머: 개념
- 카프카 컨슈머는 보통 컨슈머 그룹의 일부로서 작동함.
- 동일한 컨슈머 그룹에 속한 여러 개의 컨슈머들이 동일한 토픽을 구독할 경우, 각각의 컨슈머는 해당 토픽에서 서로 다른 파티션의 메시지를 받음.
- 컨슈머 그룹에 컨슈머를 추가하는 것은 카프카 토픽에서 읽어오는 데이터 양을 확장하는 주된 방법임.
- 컨슈머에 할당된 파티션을 다른 컨슈머에게 할당해주는 작업을 리밸런스라고 함.
  - 조급한 리밸런스: 모든 컨슈머는 읽기 작업을 멈추고 자신에게 할당된 모든 파티션에 대한 소유권을 포기한 뒤, 컨슈머 그룹에 다시 참여하여 완전히 새로운 파티션 할당을 전달받음.
  - 협력적 리밸런스: 한 컨슈머에게 할당되어 있던 파티션만을 다른 컨슈머에 재할당함.
- 컨슈머가 갖는 컨슈머 그룹의 멤버로서의 자격은 일시적임.
  - 컨슈머가 컨슈머 그룹을 떠나는 순간 해당 컨슈머에 할당되어 있던 파티션들은 해제되고, 다시 참여하면 새로운 멤버ID가 발급되면서 리밸런스 프로토콜에 의해 새로운 파티션들이 할당됨.

## 4.2 카프카 컨슈머 생성하기
```java
Properties props = new Properties();
props.put("bootstrap.servers", "broker1:9092,broker2:9092");
props.put("group.id", "CountryCounter");
props.put("key.deserializer",
    "org.apache.kafka.common.serialization.StringDeserializer");
props.put("value.deserializer",
    "org.apache.kafka.common.serialization.StringDeserializer");
KafkaConsumer<String, String> consumer =
    new KafkaConsumer<String, String>(props);
```

## 4.3 토픽 구독하기
```java
consumer.subscribe(Collections.singletonList("customerCountries"));
```
```java
consumer.subscribe(Pattern.compile("test.*"));
```

## 4.4 폴링 루프
- 폴링 루프는 단순히 데이터를 가져오는 것보다 훨씬 더 많은 일을 함.
- 새 컨슈머에서 처음으로 poll()을 호출하면 컨슈머는 GroupCoordinator를 찾아서 컨슈머 그룹에 참가하고, 파티션을 할당 받음.
- 리밸런스 역시 연관된 콜백들과 함께 여기서 처리됨.
- 컨슈머 혹은 콜백에서 뭔가 잘못 될 수 있는 거의 모든 것들은 poll()에서 예외의 형태로 발생함.
- 하나의 스레드에서 동일한 그룹 내에 여러 개의 컨슈머를 생성할 수 없으며, 같은 컨슈머를 다수의 스레드가 안전하게 사용할 수 없음.
- 하나의 스레드당 하나의 컨슈머, 이것이 원칙임.

## 4.5 컨슈머 설정하기
(...생략...)

## 4.6 커밋과 오프셋
- poll()을 호출할 때마다 카프카에 쓰여진 메시지 중 컨슈머 그룹에 속한 컨슈머들이 아직 읽지 않은 레코드가 리턴됨.
- 뒤집어 말하면, 이를 이용해서 그룹 내의 컨슈머가 어떤 레코드를 읽었는지를 판단할 수 있음.
- 카프카에서는 파티션에서의 현재 위치를 업데이트하는 작업을 오프셋 커밋이라고 부름.
- 컨슈머는 파티션에서 성공적으로 처리해 낸 마지막 메세지를 커밋함으로써 그 앞의 모든 메시지들 역시 성공적으로 처리됐음을 암묵적으로 나타냄.
- 컨슈머가 오프셋을 커밋하는 방법은 특수 토픽인 __consumer_offsets 토픽에 각 파티션별로 커밋된 오프셋을 업데이트하도록 하는 메시지를 보냄으로써 이루어짐.

## 4.7 리밸런스 리스너
- 컨슈머는 종료하기 전이나 리밸런싱이 시작되기 전에 정리 작업을 해줘야 함.
- 만약 컨슈머에 할당된 파티션이 해제될 것이라는 걸 알게 된다면 해당 파티션에서 마지막으로 처리한 이벤트의 오프셋을 커밋해야 함.
- 파일 핸들이나 데이터베이스 연결 등 역시 닫아줘야 함.

## 4.8 특정 오프셋의 레코드 읽어오기
- 지금까지는 각 파티션의 마지막으로 커밋된 오프셋부터 읽기를 시작해서 모든 메시지를 순차적으로 처리하기 위해 poll()을 사용하는 방법에 대해서만 살펴봄.
- 하지만, 다른 오프셋에서부터 읽기를 시작하고 싶은 경우가 있음.
- 카프카는 다음 번 poll() 호출이 다른 오프셋에서부터 읽기를 시작하도록 하는 다양한 메서드를 제공함.

## 4.9 폴링 루프를 벗어나는 방법
- 컨슈머를 종료하고자할 때, 컨슈머가 poll()을 오랫동안 기다리고 있더라도 즉시 루프를 탈출하고 싶다면 다른 스레드에서 consumer.wakeup()을 호출해야 함.
- 만약 메인 스레드에서 컨슈머 루프를 돌고 있다면 ShutdownHook을 사용할 수 있음.
- consumer.wakeup()은 다른 스레드에서 호출해 줄 때만 안전하게 작동하는 유일한 컨슈머 메서드임.
- wakeup을 호출하면 poll()이 WakeupException을 발생시키며 중단되거나, 대기중이 아닐 경우에는 다음 번에 처음으로 poll()가 호출될 때 예외가 발생함.
- WakeupExceuption을 딱히 처리해 줄 필요는 없지만, 스레드를 종료하기 전 consumer.close()는 호출해야 함.
- 컨슈머를 닫으면 오프셋을 커밋하고 그룹 코디네이터에게 컨슈머가 그룹을 떠난다는 메시지를 전송함.
- 이때 컨슈머 코디네이터가 즉시 리밸런싱을 실행시키기 때문에 닫고 있는 컨슈머에게 할당되어 있던 파티션들이 그룹 안의 다른 컨슈머에게 할당될 때까지 세션 타임아웃을 기다릴 필요가 없음.

## 4.10 디시리얼라이저
- 카프카 프로듀서는 카프카에 데이터를 쓰기 전 커스텀 객체를 바이트 배열로 변환하기 위해 시리얼라이저가 필요함.
- 카프카 컨슈머는 카프카로부터 받은 바이트 배열을 자바 객체로 변환하기 위해 디시리얼라이저가 필요함.
- 각 메시지의 키와 밸류가 문자열이라면, 카프카 설정의 기본값인 StringDeserializer를 사용함.
- 커스텀 시리얼라이저와 디시리얼라이저를 직접 구현하는 것은 권장되지 않음.
- 프로듀서와 컨슈머를 너무 밀접하게 연관시키는 탓에 깨지기도 쉽고 에러가 발생할 가능성도 높기 때문임.
- JSON, Thrift, Protobuf, Avro와 같은 표준 메시지 형식을 사용하는 것이 더 좋은 방법이 될 수 있음.

## 4.11 독립 실행 컨슈머: 컨슈머 그룹 없이 컨슈머를 사용해야 하는 이유와 방법
- 컨슈머 그룹은 컨슈머들에게 파티션을 자동으로 할당해주고 해당 그룹에 컨슈머가 추가되거나 제거될 경우 자동으로 리밸런싱 해줌.
- 하나의 컨슈머가 토픽의 모든 파티션으로부터 모든 데이터를 읽어와야 하거나, 토픽의 특정 파티션으로부터 데이터를 읽어와야 할 때가 있음.
- 이러한 경우 컨슈머 그룹이나 리밸런스 기능이 필요하지 않음.
- 그냥 컨슈머에게 특정한 토픽과 파티션을 할당해주고, 메시지를 읽어서 처리하고, 필요할 경우 오프셋을 커밋하면 됨.
