Chater 1 ~ Chapter 3

# Chapter 01. 카프카 시작하기

데이터 처리를 위해서는 데이터를 생성된 곳에서 분석할 수 있는 곳으로 옮겨야 한다. 

데이터를 이동시키는 작업에 더 적은 노력을 들일수록 핵심 비즈니스에 집중할 수 있다. 

데이터가 중심이 되는 기업에서 파이프라인이 중요한 핵심적인 요소가 되는 이유

## 발행/구독 메시지 전달

- 발행/구독 메시지 전달(publish/subscribe messaging)의 개념
    - 발행/구독 메시지 전달 패턴의 특징은 **전송자가 수신자로 보내지 않는다는 점.**
    - 중간 지점에 브로커(broker)가 있다는 점이 중요
- 데이터 주도 애플리케이션에서의 중요성

## 1. 초기의 발행 / 구독 시스템

- 가운데 간단한 메시지 큐나 프로세스 간 통신 채널을 놓는다.
- 그러나 지표UI, 지표분석, 활동 모니터링, 데이터베이스 모니터 등등 여러 애플리케이션이 같이 연결되게 되면 기술 부채

---

- 모든 애플리케이션으로부터 지표를 받는 하나의 애플리케이션을 만들고
- 이 지푯값들을 필요로 하는 어느 시스템이든 지표를 질의할 수 있도록 해주는 서버를 제공

---

## 2. 개별 메시지 큐 시스템

지표를 다루는 것과 동시에 로그 메시지에 대해서도 비슷한 작업을 해줘야 한다. 

- 지표값 발행 / 구독
- 로그 메시지 발행 / 구독
- 사용자 추적 발행 / 구독

---

- 다수의 데이터 큐 시스템을 유지 관리해야 함
- 비즈니스가 확장됨에 따라 함께 확장되는 일반화된 유형의 데이터를 발행하고 구독할 수 있는 중앙 집중화된 시스템이 필요

---

# 카프카

- 아파치 카프카는 메시지 발행/구독 시스템
- ‘분산 커밋 로그’ 또는 ‘분산 스트리밍 플랫폼’ 이라고 불리기도 함.
- 파일시스템이나 데이터베이스 커밋 로그는 모든 트랜잭션 기록을 지속성(durable) 있게 보관함으로써 시스템의 상태를 일관성(consistency)있게 복구할 수 있도록 고안되었다.
- 카프카에 저장된 데이터는 순서를 유지한 채로 지속성 있게 보관되며 결정적(deterministic)으로 읽을 수 있다.
- 실패가 발생하더라도 데이터 사용에는 문제가 없도록 시스템 안에서 데이터를 분산시켜 저장 가능 장점

---

## 1. 메시지와 배치

- 메시지 : 카프카에서 데이터의 기본 단위
    - 카프카의 입장에서 메시지는 단순히 바이트의 배열일 뿐이기 때문에 여기에 포함된 데이터에는 특정한 형식이나 의미가 없다.
- 메시지는 key라는 메타데이터를 포함할 수도 있다.
    - key도 카프카 입장에서는 의미없는 바이트 배열일 뿐이다.
- key는 메시지를 저장할 파티션을 결정하기 위해 사용된다.

---

가장 간단한 방법 → 파티션 수가 변하지 않는 이상 항상 같은 파티션에 저장됨.

1. key값에서 일정한 해시값을 생성
2. 이 값을 토픽의 파티션 수로 나눔
3. 나오는 나머지 값에 해당하는 파티션에 저장

---

카프카는 효율성을 위해 메시지를 배치batch 단위로 저장한다. 

- batch는 같은 토픽의 파티션에 쓰여지는 메시지들의 집합이다.
- 메시지를 쓸 때마다 네트워크상에서 신호가 오가는 것은 막대한 오버헤드를 발생하기 때문에, 메시지를 batch 단위로 모아서 써서 이걸 줄인다.
- 물론 latency와 throughput 사이의 트레이드오프를 발생시킨다.
    - 배치 크기가 커질수록 시간당 처리되는 메시지의 수는 늘어나지만, 메시지가 전달되는데 걸리는 시간은 늘어난다.

---

## 2. 스키마

- 스키마 : 일정한 구조 (ex. JSON, XML, 아파치 Avro)
- 아파치 에이브로 : 메시지 본체와 스키마 분리 → 스키마 변경되더라도 코드 생성할 필요 x
- 메시지 읽기와 쓰기를 위해서 일관적인 데이터 형식이 중요

---

## 3. 토픽과 파티션

- 토픽 : 카프카 메시지 구성 단위
    - ex. 파일시스템의 폴더, 데이터베이스 테이블
- 파티션 : 토픽의 구성 단위
    - ex. 로그의 경우 하나의 로그가 파티션에 해당
- 파티션에 메시지 쓰여질 때 → 추가만 가능한 형태(append only)

---

- 토픽 안, 메시지 전체에 대해서는 순서 보장 x
- 단일 파티션 안에서는 순서 보장

---

- 파티션
    - 카프카가 데이터 중복과 확장성을 제공하는 방법
    - 각 파티션이 서로 다른 서버에 저장 가능
        - 따라서, 하나의 토픽이 여러 개의 서버에 확장되어 하나의 서버의 용량을 넘어가는 성능을 보여줌.
    - 파티션은 복제될 수 있다.
        - 서로 다른 서버들이 동일한 파티션의 복제본을 저장 → 서버 중 하나에 장애가 발생한다고 해서 읽거나 쓸 수 없는 상황이 벌어지지는 않는다.

---

- 스트림(stream)
    - (파티션 개수와 상관없이) 하나의 토픽에 저장된 데이터로 간주
    - producer 로부터 consumer 까지의 데이터 흐름을 나타냄
    - 메시지를 실시간으로 처리하는 stream processing
        - cf> Hadoop은 데이터를 시간이 흐른 뒤 한꺼번에 처리하는 오프라인 프레임워크

---

## 4. 프로듀서와 컨슈머

- 카프카 클라이언트
    - 종류 : 프로듀서, 컨슈머, 카프카 커넥트 API, 카프카 스트림즈
        - 카프카 커넥트 API, 카프카 스트림즈 : 프로듀서, 컨슈머를 기본으로 사용하고 추가 기능 제공함
- 프로듀서 : 새로운 메시지 생성
    - 메시지는 specific topic에 씀
    - 메시지를 쓸 때 토픽에 속한 파티션들 사이에 고르게 나눠서 씀.
        - 특정 파티션 지정도 가능
    - 동일한 키값을 가진 모든 메시지 → 같은 파티션이 저장
        - 파티셔너 : 키값의 해시를 특정 파티션으로 대응시켜줌
- 컨슈머 : 메시지를 읽음
    - 메시지의 오프셋 기록 → 어느 메시지까지 읽었는지 유지
        - 오프셋 : 증가하는 정수값
        - 메시지 저장 시 메시지에 부여하는 메타데이터
    - 읽기 작업 정지 후 다시 시작해도 문제없음
    - 컨슈머 그룹 : 컨슈머 집합
        - 각 파티션이 하나의 컨슈머에 의해서만 읽히도록 함.(파티션 하나에는 컨슈머 하나만 연결됨)
        - 컨슈머의 파티션 ownership : 컨슈머 → 파티션 대응 관계
    - consumer group을 통해 대량의 메시지를 갖는 토픽들을 읽기 위해 컨슈머들 수평 확장 가능
    - 컨슈머 중 하나 장애가 발생해도 다른 컨슈머가 재할당받아서 읽을 수 있다.

---

## 5. 브로커와 클러스터

- 브로커 : 하나의 카프카 서버
    1. 프로듀서로부터 메시지를 전달받음
    2. 오프셋 할당
    3. 디스크 저장소에 씀
    4. 컨슈머의 읽기(fetch) 요청 처리, 발행된 메시지 보내줌
- 하나의 브로커 → 초당 수천 개의 파티션과 수백만 개의 메시지 처리 가능
- 카프카 브로커 → 클러스터로 구성
    - 하나의 클러스터 안에 여러 개의 브로커
    - 컨트롤러(브로커 중 하나) : 파티션을 브로커에 할당해주는 역할, 장애가 발생한 브로커 모니터링하는 관리 기능
    - 파티션 → 클러스터 안의 브로커 중 하나가 담당, 파티션 리더라고 부름
    - 복제된 파티션이 여러 브로커에 할당 → 파티션의 팔로워
    - 복제 기능 : 파티션의 메시지를 중복 저장함으로써 리더 브로커에 장애가 발생했을 때 팔로워 중 하나가 리더 역할을 이어받을 수 있도록 함.
    - 모든 프로듀서는 리더 브로커에 메시지를 발행해야함 / 컨슈머는 리더나 팔로워 중 하나로부터 데이터 읽어옴.
- 로그 압창 : 같은 키를 갖는 메시지 중 가장 최신의 것만 보존된다.
    - 마지막 변경값이 중요한 체인지로그 형태의 데이터에 사용

---

## 6. 다중 클러스터

- 다중 클러스터의 장점
    - 데이터 유형별 분리
    - 보안 요구사항 충족
    - 재해 복구 대비 다중 데이터 센터
- 카프카가 다수의 데이터 센터에서 운용 → 데이터 센터간의 메시지 복제 필요.
- 카프카 클러스터의 복제 메커니즘은 다중 클러스터 사이에서가 아닌 하나의 클러스터 안에서만 작동하도록 설계됨.
- MirrorMaker : 데이터를 다른 클러스터로 복제하는 데 사용됨.
    - 큐로 연결된 카프카 컨슈머와 프로듀서

---

# 왜 카프카?

pub/sub은 여러 가지인데 왜 카프카?

## 1. 다중 프로듀서

- 여러 프로듀서를 처리할 수 있다.
- 프로듀서 클라이언트가 여러 토픽을 사용하든 하나의 토픽을 사용하든 상관없음.
- 많은 프론트엔드 시스템으로부터 데이터 수집하고, 일관성 유지에 적격
- 컨슈머 애플리케이션은 애플리케이션 별로 하나씩, 여러 개의 토픽에서 데이터를 읽어올 필요 없이 모든 애플리케이션에 대한 페이지 뷰 스트림 하나만 읽어오면 된다.

---

## 2. 다중 컨슈머

- 많은 컨슈머가 상호 간섭 없이 메시지 스트림을 읽을 수 있도록 설게됨.
- 하나의 메시지를 하나의 클라이언트에서만 소비할 수 있도록 되어 있는 큐 시스템과의 차이.

---

## 3. 디스크 기반 보존

- 메시지를 지속성 있게 저장 → 컨슈머들이 항상 실시간으로 데이터 읽어올 필요 없다
- 컨슈머를 정지하더라도 메시지는 카프카 안에 남아있게 된다.

---

## 4. 확장성

- 시스템 전체의 가용성에 영향 주지 않으면서 확장 가능
- 동시다발적인 장애를 견뎌야 하는 클러스터의 경우 더 큰 복제 팩터(RF)를 설정하는 것이 가능

---

## 5. 고성능

---

## 6. 플랫폼 기능

- API와 라이브러리 형태로 사용 가능
- 카프카 커넥트 : 소스 데이터 시스템으로부터 카프카로 데이터를 가져오거나 카프카의 데이터를 싱크 시스템으로 내보내는 역할
- 카프카 스트림즈 : 규모 가변성과 내고장성을 갖춘 스트림 처리 애플리케이션을 쉽게 개발할 수 있게 해주는 라이브러리.

---

## **데이터 생태계, 카프카의 활용 사례**

카프카는 데이터 생태계에 있어서 순환 시스템 제공

프로듀서와 컨슈머는 어떤 형태로든 연결될 필요가 없다. 

프로듀서는 누가 데이터를 사용하는지 신경 쓸 필요가 없다. 

### 이용 사례

- **활동 추적**
    - 사용자 클릭 로그, 애플리케이션 사용 데이터 수집 및 분석
- **메시지 교환**
    - 서로 다른 시스템 간 데이터를 일정한 포맷으로 교환
- **지표 및 로그 수집**
    - 서버 로그와 지표 데이터를 실시간으로 수집
- **커밋 로그**
    - 데이터베이스 커밋 로그를 발행하여 실시간 변경 사항 전달
- **스트림 처리**
    - 데이터를 실시간으로 처리하여 분석 및 응답

---

## **카프카의 기원**

- 링크드인의 모니터링 시스템 개선을 위해 시작
- 기존 문제: 긴 지표 수집 주기와 높은 유지보수 비용
- 카프카가 해결한 주요 요구사항
    - 발행자와 구독자 분리
    - 메시지 영속적 저장
    - 높은 메시지 처리량과 수평적 확장성 제공

---

# Chapter 02