## 6. 카프카 내부 메커니즘

### 컨트롤러

- Kafka에서 컨트롤러(Controller)는 카프카 브로커 기능 + 파티션 리더를 선출하는 역할
- 주키퍼의 /controller에 노드로 생성되어 컨트롤러가 됨
- 브로커가 컨트롤러가 되면, 클러스터 메타데이터 관리와 리더 선출을 시작하기 전 주키퍼로부터 최신 레플리카 상태 맵을 읽어옴
  - 비동기 API로 작동하지만, 파티션 수가 많은 클러스터에선 몇초씩 걸릴 수 있음
- 브로커가 클러스터에서 나가서 새로운 리더 선출 및 팔로워 정보를 뿌리는것도 비동기로 작동하나, 그 수에 따라 지연가능
___

#### KRaft: 카프카의 새로운 래프트 기반 컨트롤러

주키퍼기반 컨트롤러로부터 탈피해서 래프트기반 컨트롤러 쿼럼으로 옮겨감

- 컨트롤러가 주키퍼에 메타데이터를 쓰는 작업은 동기적, 브로커에 메시지를 보내는 작업은 비동기, 주키퍼로부터 업데이트를 받는 과정도 비동기
  -> 브로커, 컨트롤러, 주키퍼 간 메타데이터 불일치 발생가능
-  컨트롤러 재시작 시 주키퍼로부터 모든 브로커와 파티션에 대한 메타데이터를 읽어와서 브로커로 전송해야 함
  -> 병목 지점, 파티션, 브로커의 수가 증가함에 따라 더 느려짐 (파티션, 브로커 수는 계속 증가할 것)
- 주키퍼 그 자체로 분산시스템이라, 카프카를 사용하려는 개발자들은 두 개의 분산 시스템에 대해 배워야 함

=> 주키퍼 기반 컨트롤러를 교체하는 방향

주키퍼의 중요 기능
- 컨트롤러 선출
- 클러스터 메타데이터 (브로커, 설정, 토픽, 파티션, 레플리카) 저장

=> 새로운 컨트롤러
- 컨트롤러 노드들이 메타데이터 이벤트 로그를 관리하는 래프트 쿼럼 (클러스터 노드), 메타데이터 변경 내역 및 정보들을 저장할 용도
- 메타데이터 로그의 리더 - 액티브 컨트롤러, 그 외는 팔로워 컨트롤러, 팔로워가 Pull하는 방식 -> 장애 복구 시 reload 시간이 필요없음
- 변경 사항을 오프셋으로 추적하여 Incremental 방식으로 업데이트하며 시동 시간을 줄이기위해 디스크에 저장
```
controller.quorum.voters=1@controller1.example.com:9093,2@...
listeners=PLAINTEXT://:9092,CONTROLLER://:9093  // 브로커와 컨트롤러 역할 둘 다 할 시
```
___

### 복제

카프카는 분산되고 분할되고 복제된 커밋 로그 서비스로 표현되기도 한다.

복제가 중요한 이유는 개별적인 노드에 필연적으로 장애가 발생할 수밖에 없는 상황에서 카프카가 신뢰성과 지속성을 보장하는 방식이기 때문이다.

**리더 레플리카**
- 모든 쓰기 요청을 수행함
- 어느 팔로워 레플리카가 리더 레플리카의 최신 상태를 유지하고 있는지를 확인함. (10초 이상 확인 안되면 out-of-sync replica)
- 리더가 장애가 발생하면, Kafka의 컨트롤러가 ISR(In-Sync Replica)중 하나를 새로운 리더로 승격함.
- ISR은 리더와 동기화 상태를 유지하고 있는 레플리카들의 집합

**팔로워 레플리카**
- 파티션에 속한 모든 레플리카 중에서 리더 레플리카를 제외한 나머지
- 리더 레플리카로 들어온 최근 메시지들을 복제함으로써 최신 상태 유지함

```
브로커 3개가 클러스터를 이루고 있다면 토픽A의 1번 파티션에 대한 리더는 1번 브로커
토픽A의 2번 파티션에 대한 리더는 2번 브로커 형식으로 이루어질 수 있다.
```
___

### 요청 처리

카프카 브로커가 하는 일의 대부분은 `클라이언트, 파티션 레플리카, 컨트롤러가 파티션 리더`에게 보내는 요청을 처리하는 것이다.

**Apache Kafka Broker 내부 요청 처리**
- 카프카 브로커의 내부 요청 처리는 Kafka 클러스터가 데이터 Produce와 Consume을 안정적으로 수행할 수 있도록 설계된 메커니즘
- 브로커는 클라이언트(프로듀서/컨슈머)의 요청을 처리하고 **클러스터 내부의 데이터 복제와 상태 관리 요청을 조율함**
- Apache Kafka 브로커의 내부에는 요청(Request)을 처리하기 위한 다양한 스레드 모델리 설계되어 있음.
  - Acceptor 스레드: 클라이언트(프로듀서, 컨슈머 등) 또는 다른 브로커의 연결 요청을 수신함. 그리고 새로운 TCP 연결을 수락(accept)하고 이 연결을 적절한 Processor 스레드로 전달함.
  - Processor 스레드(num.network.threads): Processor 스레드는 Acceptor로부터 전달받은 TCP연결을 통해 요청(Request)을 읽고, 처리 후 응답(Response)을 생성함
  - I/O 스레드(num.io.threads): Kafka 클러스터 내부에서 데이터 복제를 담당함. 팔로워 브로커는 리더 브로커로부터 데이터를 요청(Fetch Request)하고, 이를 자신의 복제로그에 저장함.
<img width="940" alt="스크린샷 2025-03-30 오후 9 14 18" src="https://github.com/user-attachments/assets/89e3b3e6-9930-49c8-9bdd-e5c38028b4eb" />

___
**메타데이터 요청 처리**
- 클라이언트(Producer/Consumer/Admin)가 Kafka 클러스터에 대한 정보를 요청하는 작업
- 메타데이터에는 각 파티션 리더가 누구인지 등의 데이터를 캐시해놓고, Not a Leader 응답이 올 시 메타데이터 갱신 요청을 한 후 메타데이터에 저장된 리더에 요청을 보내는 방식
- 메타데이터 요청은 Kafka 클러스터의 다음과 같은 정보를 반환함
  - 토픽 및 파티션 정보
    - 클러스터에 있는 토픽의 목록
    - 각 토픽의 파티션 개수
    - 각 파티션의 리더(Leader)와 복제본(Replicas)정보
  - 브로커 정보
    - Kafka Cluster에 있는 브로커의 목록
    - 각 브로커의 ID와 호스트 이름
  - 파티션 상태
    - 특정 토픽의 각 파티션에 대한 리더 브로커 ID
    - ISR(In-Sync Replica) 목록
<img width="940" alt="스크린샷 2025-03-30 오후 9 14 41" src="https://github.com/user-attachments/assets/6e80a78a-2a39-4b63-bf5d-4f32be4841c0" />

___

### 쓰기 요청

프로듀서가 Kafka 브로커에 데이터를 보낼 때 사용하는 요청

acks: 브로커는 요청에 대한 성공 여부를 프로듀서에 응답함.
- acks=0: 브로커의 응답을 기다리지 않음
- acks=1: 리더에만 메시를 받으면 성공 확인
- acks=all: ISR에 있는 모든 레플리카로 데이터가 복제되었을 때

요청 흐름 (acks=all)

1. 프로듀서 → 리더 브로커 (쓰기 요청)
2. 리더 브로커 → 팔로워 브로커 (데이터 복제)
3. 리더 브로커 → 프로듀서(ACK 응답)

### 읽기 요청

1. 클라이언트는 브로커에 토픽, 파티션 그리고 오프셋 목록에 해당하는 메시지들을 보내 달라는 요청을 보낸다.
```
이때, 클라이언트는 각 파티션에 대해 브로커가 리턴할 수 있는 최대 데이터의 양 역시 지정한다. (클라이언트가 못받는 큰 응답)
"보낼 데이터가 최소한 10K 바이트 쌓이면 결과를 리턴하라" 라고 데이터 양을 지정할 수 있다.
```

2. 파티션 리더가 요청을 받아 유효한 요청인지, 오프셋이 해당 파티션에 존재하는 지 등을 확인한다. 

3. 브로커는 파티션으로부터 클라이언트가 요청에 지정한 max 까지 메시지를 읽어서 보내주며, 파일에서 읽어온 데이터를 중간 버퍼 없이 네트워크로 바로 흘려주는 `Zero copy` 최적화를 적용

4. 브로커가 충분한 데이터를 가질 때까지 클라이언트가 마냥 기다리기만 하는 것을 원하지는 않을때 타임아웃을 지정할 수 있다.
```
"만약 x밀리초 안에 하한만큼의 데이터가 모이지 않으면 그냥 있는 것이라도 보내라"
파티션 리더에 존재하는 모든 데이터를 클라이언트가 읽을 수 있는 건 아니다. 대부분의 클라이언트는 모든 인-싱크 레플리카에 쓰여진 메시지들만 읽을 수 있을 뿐이다. 왜냐하면 충분한 수의 레플리카에 복제가 완료되지 않은 메시지는 불안전한 것으로 간주되기 때문이다.
```

5. 읽기 세션 캐시(Fetch Session Cache) 사용하여 컨슈머는 읽고 있는 파티션의 목록과 그 메타데이터를 캐시하는 세션을 생성할 수 있다.
   읽고자 하는 파티션의 집합이나 여기에 연관된 메타데이터는 여간해서는 잘 바뀌지 않는 데다가, 많은 경우 리턴해야 할 메타데이터가 그렇게 많지도 않기 때문이다.

=> 컨슈머는 매 요청마다 모든 파티션 지정없이 점진적으로 읽어나갈 수 있게됨

___

## 물리적 저장소

카프카의 기본 저장 단위: 파티션 레플리카 (Partition Replica)
카프카가 데이터를 저장하기 위해 사용 가능한 디렉토리 활용 방법
1. 데이터가 클러스터 안의 브로커, 브로커 안의 디렉토리에 할당되는 방식
2. 브로커가 파일을 관리하는 방법
3. 파일 내부로 초점을 옮겨 데이터가 저장되는 파일과 인덱스 형식
4. 카프카를 장시간용 데이터 저장소로 사용할 수 있게 해주는 고급 기능인 로그 압착 기능, 작동원리
